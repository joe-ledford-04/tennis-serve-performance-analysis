{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "tags": [
     "Macro Data Refinement"
    ]
   },
   "source": [
    "from statistics import linear_regression\n",
    "\n",
    "# importing libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Loading and merging refined yearly ATP data\n",
    "years = list(range(2010, 2024))\n",
    "dfs = []\n",
    "for year in years:\n",
    "    file_path = f'data/atp_matches_{year}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['year'] = year\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# cleaning column names and dropping missing values\n",
    "df_all.columns = [col.strip().lower().replace(' ', '_') for col in df_all.columns]\n",
    "df_all = df_all.dropna(subset=['w_ace','w_df','w_svpt', 'w_1stin', 'w_1stwon', 'w_2ndwon', 'w_svgms','w_bpsaved','w_bpfaced', 'l_ace','l_df', 'l_svpt','l_1stin', 'l_1stwon', 'l_2ndwon', 'l_svgms','l_bpsaved','l_bpfaced', 'winner_ioc', 'loser_ioc', 'tourney_name'])\n",
    "\n",
    "# dropping incomplete rows\n",
    "df_all = df_all.dropna(subset=['w_ace','w_df','w_svpt', 'w_1stin', 'w_1stwon', 'w_2ndwon', 'w_svgms','w_bpsaved','w_bpfaced', 'l_ace','l_df', 'l_svpt','l_1stin', 'l_1stwon', 'l_2ndwon', 'l_svgms','l_bpsaved','l_bpfaced', 'winner_ioc', 'loser_ioc', 'tourney_name'])\n",
    "\n",
    "# Mapping tournament names to host countries\n",
    "tourney_to_country = {\n",
    "    'Brisbane': 'AUS', 'Chennai': 'IND', 'Doha': 'QAT', 'Auckland': 'NZL',\n",
    "    'Sydney': 'AUS', 'Australian Open': 'AUS', 'Johannesburg': 'RSA',\n",
    "    'Santiago': 'CHI', 'Zagreb': 'CRO', 'Costa Do Sauipe': 'BRA',\n",
    "    'Rotterdam': 'NED', 'San Jose': 'USA', 'Buenos Aires': 'ARG',\n",
    "    'Marseille': 'FRA', 'Memphis': 'USA', 'Acapulco': 'MEX',\n",
    "    'Delray Beach': 'USA', 'Dubai': 'UAE', 'Indian Wells Masters': 'USA',\n",
    "    'Miami Masters': 'USA', 'Casablanca': 'MAR', 'Houston': 'USA',\n",
    "    'Monte Carlo Masters': 'MCO', 'Barcelona': 'ESP', 'Rome Masters': 'ITA',\n",
    "    'Munich': 'GER', 'Belgrade': 'SRB', 'Estoril': 'POR',\n",
    "    'Madrid Masters': 'ESP', 'Dusseldorf': 'GER', 'Nice': 'FRA',\n",
    "    'Roland Garros': 'FRA', 'Halle': 'GER', \"Queen's Club\": 'GBR',\n",
    "    'Eastbourne': 'GBR', \"s Hertogenbosch\": 'NED', 'Wimbledon': 'GBR',\n",
    "    'Newport': 'USA', 'Atlanta': 'USA', 'Hamburg': 'GER', 'Gstaad': 'SUI',\n",
    "    'Los Angeles': 'USA', 'Umag': 'CRO', 'Washington': 'USA',\n",
    "    'Canada Masters': 'CAN', 'Cincinnati Masters': 'USA', 'New Haven': 'USA',\n",
    "    'US Open': 'USA', 'Bucharest': 'ROU', 'Metz': 'FRA', 'Bangkok': 'THA',\n",
    "    'Kuala Lumpur': 'MAS', 'Beijing': 'CHN', 'Tokyo': 'JPN',\n",
    "    'Shanghai Masters': 'CHN', 'Moscow': 'RUS', 'Stockholm': 'SWE',\n",
    "    'Montpelier': 'FRA', 'St. Petersburg': 'RUS', 'Vienna': 'AUT',\n",
    "    'Valencia': 'ESP', 'Basel': 'SUI', 'Paris Masters': 'FRA', 'Tour Finals': 'GBR',\n",
    "}\n",
    "\n",
    "# combining all \"bad\" tournaments into a single regex pattern & filtering them out\n",
    "pattern = 'Davis Cup|Laver Cup|Tokyo Olympics|Dusseldorf'\n",
    "df_all = df_all[~df_all['tourney_name'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# standardizes spacing\n",
    "df_all['tourney_name'] = df_all['tourney_name'].str.strip()\n",
    "\n",
    "# creating home dummy var\n",
    "df_all['tourney_name'] = df_all['tourney_name'].str.strip()\n",
    "df_all['tourney_country'] = df_all['tourney_name'].map(tourney_to_country)\n",
    "\n",
    "# home dummy for winner\n",
    "df_all['winner_home'] = (df_all['winner_ioc'] == df_all['tourney_country']).astype(int)\n",
    "# home dummy for loser (if needed)\n",
    "df_all['loser_home'] = (df_all['loser_ioc'] == df_all['tourney_country']).astype(int)\n",
    "\n",
    "\n",
    "# saving clean data\n",
    "df_all.to_csv('data/atp_matches_cleaned.csv', index=False)\n",
    "\n",
    "# mapping round number\n",
    "round_order = {'R128':1, 'R64':2,'R32':3,'R16':4,'QF':5,'SF':6,'F':7}\n",
    "df_all['round_num'] = df_all['round'].map(round_order)\n",
    "\n",
    "\n",
    "# winner dataframe\n",
    "winner_df = df_all[['tourney_id','tourney_name','tourney_level', 'tourney_country', 'surface', 'year',\n",
    "                    'winner_name', 'winner_ioc',\n",
    "                    'w_ace', 'w_df', 'w_svpt', 'w_1stin', 'w_1stwon', 'w_2ndwon',\n",
    "                    'w_svgms', 'w_bpsaved', 'w_bpfaced']].copy()\n",
    "\n",
    "winner_df['home'] = (winner_df['winner_ioc'] == winner_df['tourney_country'])\n",
    "winner_df.columns = ['tourney_id','tourney_name','tourney_level', 'tourney_country', 'surface', 'year', 'player_name', 'player_ioc', 'aces', 'double_faults', 'svpt',\n",
    "                     'first_in', 'first_won', 'second_won', 'service_games',\n",
    "                     'break_points_saved', 'break_points_faced', 'home']\n",
    "\n",
    "# loser dataframe\n",
    "loser_df = df_all[['tourney_id', 'tourney_name','tourney_level', 'tourney_country', 'surface', 'year', 'loser_name','loser_ioc', 'l_ace','l_df', 'l_svpt','l_1stin', 'l_1stwon', 'l_2ndwon', 'l_svgms','l_bpsaved','l_bpfaced']].copy()\n",
    "loser_df['home'] = (loser_df['loser_ioc'] == loser_df['tourney_country'])\n",
    "loser_df.columns = ['tourney_id', 'tourney_name', 'tourney_level', 'tourney_country', 'surface', 'year',\n",
    "                    'player_name', 'player_ioc', 'aces', 'double_faults', 'svpt',\n",
    "                    'first_in', 'first_won', 'second_won', 'service_games',\n",
    "                    'break_points_saved', 'break_points_faced', 'home']\n",
    "\n",
    "frames = [winner_df, loser_df]\n",
    "player_df = pd.concat(frames, ignore_index=True)\n",
    "player_df.columns = [col.strip().lower().replace(' ', '_') for col in player_df.columns]\n",
    "# dropping matches with 0 or missing serve games\n",
    "player_df = player_df[player_df['service_games'] > 0]\n",
    "\n",
    "# grouping tournaments with the same length\n",
    "player_df = player_df.merge(df_all[['tourney_id', 'round', 'round_num']], on='tourney_id', how='left')\n",
    "\n",
    "# first serve percentage metric\n",
    "player_df['first_serve_pct'] = player_df['first_in'] / player_df['svpt']\n",
    "\n",
    "# player/tourney id tracking\n",
    "player_df['player_tourney_id'] = player_df['player_name'] + '_' + player_df['tourney_id']\n",
    "\n",
    "player_df = player_df.dropna(subset=['first_serve_pct', 'round_num'])\n",
    "grouped = player_df.groupby(['player_tourney_id', 'round_num']).agg({'first_serve_pct': 'mean'}).reset_index()\n",
    "\n",
    "# grouping\n",
    "grouped = player_df.groupby(['player_tourney_id', 'round_num']).agg({'first_serve_pct': 'mean'}). reset_index()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Pooled OLS Model"
    ]
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# cleaning\n",
    "player_df = player_df.dropna(subset = ['first_in', 'svpt'])\n",
    "player_df = player_df[player_df['svpt'] > 0]\n",
    "\n",
    "\n",
    "sample_ids = grouped['player_tourney_id'].drop_duplicates().sample(5,random_state=1)\n",
    "\n",
    "for ptid in sample_ids:\n",
    "    temp = player_df[player_df['player_tourney_id']==ptid].sort_values('round_num')\n",
    "    plt.plot(temp['round_num'], temp['first_serve_pct'], marker = 'o', label=ptid[:15])\n",
    "plt.xlabel('Round Number')\n",
    "plt.ylabel('First Serve %')\n",
    "plt.title('First Serve % by Round (Sample Player-Tournament Paths)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df_model = player_df.dropna(subset = ['first_serve_pct', 'round_num'])\n",
    "X = df_model[['round_num']]\n",
    "y = df_model['first_serve_pct']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\", model.coef_[0])\n",
    "print(\"R-squared:\", r2_score(y, y_pred))\n",
    "\n",
    "player_df['first_in'] = player_df['first_in'].astype(float)\n",
    "player_df['svpt'] = player_df['svpt'].astype(float)"
   ],
   "id": "d52d563d9d944de6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Pooled OLS Model.v2"
    ]
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# polynomial features (degree 2 = quadratic)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(df_model[['round_num']])\n",
    "\n",
    "# fitting model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_poly, y)\n",
    "y_pred_poly = poly_model.predict(X_poly)\n",
    "\n",
    "# results\n",
    "print(\"Intercept:\", poly_model.intercept_)\n",
    "print(\"Coefficients:\", dict(zip(poly.get_feature_names_out(['round_num']), poly_model.coef_)))\n",
    "print(\"R-squared (Polynomial):\", r2_score(y, y_pred_poly))\n"
   ],
   "id": "a249f26d285fb5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model"
    ]
   },
   "cell_type": "code",
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# cleaning\n",
    "fe_df = player_df.dropna(subset=['first_serve_pct', 'round_num', 'player_name'])\n",
    "\n",
    "# Top 25 players\n",
    "top_players = fe_df['player_name'].value_counts().head(25).index\n",
    "fe_sample = fe_df[fe_df['player_name'].isin(top_players)]\n",
    "\n",
    "# sample max: 1000 total observations (too large to run)\n",
    "fe_sample = fe_sample.sample(1000, random_state=1)\n",
    "\n",
    "# fixed effects regression\n",
    "model_fe = smf.ols('first_serve_pct ~ round_num + C(player_name)', data=fe_sample).fit()\n",
    "print(model_fe.summary())\n"
   ],
   "id": "421781c61bffc9d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Comparison of Pooled OLS & Fixed Effects "
    ]
   },
   "cell_type": "code",
   "source": [
    "import statsmodels.formula.api as smf\n",
    "# baseline pooled OLS model\n",
    "model_pooled = smf.ols('first_serve_pct ~ round_num', data=fe_sample).fit()\n",
    "\n",
    "# fixed effects model with player dummies\n",
    "model_fe = smf.ols('first_serve_pct ~ round_num + C(player_name)', data=fe_sample).fit()\n",
    "\n",
    "# F-test\n",
    "f_stat, p_value, df_diff = model_fe.compare_f_test(model_pooled)\n",
    "\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4e}\")  # scientific notation for small p-values\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "\n",
    "# model refinement\n",
    "print(\"Pooled OLS AIC\", model_pooled.aic)\n",
    "print(\"Fixed Effects AIC\", model_fe.aic)\n",
    "print(\"Pooled OLS BIC\", model_pooled.bic)\n",
    "print(\"Fixed Effects BIC\", model_fe.bic)"
   ],
   "id": "e7c9ffabd7e8f6ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "Surface Control "
    ]
   },
   "cell_type": "code",
   "source": [
    "# extracting round number coefficient\n",
    "print(\"Coefficient for Round Number: \", model_fe.params['round_num'])\n",
    "\n",
    "# control for surface\n",
    "# surface dummies from full fixed effects data\n",
    "fe_df['surface'] = pd.Categorical(fe_df['surface'], categories=['Hard', 'Clay', 'Grass'], ordered=False)\n",
    "surface_dummies = pd.get_dummies(fe_df['surface'], drop_first=True)  # Drops 'Hard' baseline\n",
    "fe_surface_df = pd.concat([fe_df, surface_dummies], axis=1)\n",
    "\n",
    "# filtering top players for sampling\n",
    "top_players = fe_surface_df['player_name'].value_counts().head(25).index\n",
    "fe_surface_sample = fe_surface_df[fe_surface_df['player_name'].isin(top_players)]\n",
    "fe_surface_sample = fe_surface_sample.sample(1000, random_state=1)\n",
    "\n",
    "# fixed effects model with surface controls\n",
    "model_fe_surface = smf.ols(\n",
    "    formula='first_serve_pct ~ round_num + Clay + Grass + C(player_name)',\n",
    "    data=fe_surface_sample\n",
    ").fit()\n",
    "\n",
    "print(model_fe_surface.summary())\n",
    "\n",
    "# f-test comparing original fixed effects model and version with surface control\n",
    "f_stat, p_value, df_diff = model_fe_surface.compare_f_test(model_fe)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "\n",
    "# f-test comparing the addition of clay and grass surface controls\n",
    "model_fe_refit = smf.ols('first_serve_pct ~ round_num + C(player_name)', data=fe_surface_sample).fit()\n",
    "f_stat, p_value, df_diff = model_fe_surface.compare_f_test(model_fe_refit)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "# AIC & BIC for Model Quality\n",
    "print(\"AIC without surface:\", model_fe_refit.aic)\n",
    "print(\"AIC with surface:\", model_fe_surface.aic)\n",
    "print(\"BIC without surface:\", model_fe_refit.bic)\n",
    "print(\"BIC with surface:\", model_fe_surface.bic)"
   ],
   "id": "f61e31666758b04f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "Year and Tournament Level Controls"
    ]
   },
   "cell_type": "code",
   "source": [
    "# adding year and tournament-level controls\n",
    "model_fe_controls = smf.ols(\n",
    "    'first_serve_pct ~ round_num + C(surface) + C(year) + C(tourney_level) + C(player_name)',\n",
    "    data=fe_surface_sample\n",
    ").fit()\n",
    "\n",
    "print(model_fe_controls.summary())\n",
    "\n",
    "# AIC, BIC, and R^2 for Quality Control\n",
    "print(\"AIC:\", model_fe_controls.aic)\n",
    "print(\"BIC:\", model_fe_controls.bic)\n",
    "print(\"R-squared (adj):\", model_fe_controls.rsquared_adj)"
   ],
   "id": "d10c830d75cc50fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     " Fixed Effects Model",
     "Interaction Effects",
     "round number x surface"
    ]
   },
   "cell_type": "code",
   "source": [
    "# ensuring surface is categorical for sample\n",
    "fe_sample['surface'] = pd.Categorical(fe_sample['surface'], categories =['Hard', 'Clay', 'Grass'])\n",
    "model_fe_interaction = smf.ols(\n",
    "    'first_serve_pct ~ round_num * surface + C(player_name)',\n",
    "    data=fe_sample\n",
    ").fit()\n",
    "print(model_fe_interaction.summary())\n",
    "\n",
    "# Model Comparison\n",
    "f_stat, p_value, df_diff = model_fe_interaction.compare_f_test(model_fe_surface)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "\n",
    "# AIC, BIC, and Adj. R^2 for Quality Control\n",
    "print(\"AIC:\", model_fe_interaction.aic)\n",
    "print(\"BIC:\", model_fe_interaction.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_interaction.rsquared_adj)"
   ],
   "id": "e1060b4daf8857b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "Double Faults Per Game Metric"
    ]
   },
   "cell_type": "code",
   "source": [
    "# double faults per game metric & cleaning\n",
    "player_df['double_faults_per_game'] = player_df['double_faults'] / player_df['service_games']\n",
    "player_df.dropna(subset =['double_faults_per_game','round_num'])\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_doubles_a = smf.ols(\n",
    "    formula = 'double_faults_per_game ~ round_num + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "print(model_fe_doubles_a.summary())\n",
    "\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_doubles_a.aic)\n",
    "print(\"BIC:\", model_fe_doubles_a.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_doubles_a.rsquared_adj)\n",
    "\n",
    "\n"
   ],
   "id": "926e4068bdb20897",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     " Fixed Effects Model",
     "Double Faults Per Game Metric",
     "Added Surface Control"
    ]
   },
   "cell_type": "code",
   "source": [
    "# double faults per game metric & cleaning\n",
    "player_df['double_faults_per_game'] = player_df['double_faults'] / player_df['service_games']\n",
    "player_df.dropna(subset =['double_faults_per_game','round_num'])\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_double_b = smf.ols(\n",
    "    formula = 'double_faults_per_game ~ round_num + +C(surface, Treatment(reference = \"Hard\")) + C(player_name)',\n",
    "    data=fe_sample\n",
    ").fit()\n",
    "print(model_fe_double_b.summary())\n",
    "\n",
    "# f-test\n",
    "f_stat, p_value, df_diff = model_fe_doubles_a.compare_f_test(model_fe_double_b)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_doubles_a.aic)\n",
    "print(\"BIC:\", model_fe_doubles_a.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_doubles_a.rsquared_adj)"
   ],
   "id": "8ff1efb97036f98c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "Break Points Saved % Metric"
    ]
   },
   "cell_type": "code",
   "source": [
    "# break points saved % metric & cleaning\n",
    "player_df = player_df.dropna(subset=['break_points_saved', 'break_points_faced'])\n",
    "player_df = player_df[player_df['break_points_faced'] > 0]\n",
    "player_df['break_points_saved_pct'] = player_df['break_points_saved'] / player_df['break_points_faced']\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_bps_pct_a = smf.ols(\n",
    "    formula = 'break_points_saved_pct ~ round_num + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "print(model_fe_bps_pct_a.summary())\n",
    "\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_doubles_a.aic)\n",
    "print(\"BIC:\", model_fe_doubles_a.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_bps_pct_a.rsquared_adj)\n"
   ],
   "id": "ae11c5b82676eec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "Break Points Saved % Metric",
     "Added Surface Control"
    ]
   },
   "cell_type": "code",
   "source": [
    "# break points saved % metric & cleaning\n",
    "player_df = player_df.dropna(subset=['break_points_saved', 'break_points_faced'])\n",
    "player_df = player_df[player_df['break_points_faced'] > 0]\n",
    "player_df['break_points_saved_pct'] = player_df['break_points_saved'] / player_df['break_points_faced']\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_bps_pct_b = smf.ols(\n",
    "    formula = 'break_points_saved_pct ~ round_num + C(surface, Treatment(reference = \"Hard\")) + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "print(model_fe_bps_pct_b.summary())\n",
    "\n",
    "# f-test\n",
    "f_stat, p_value, df_diff = model_fe_bps_pct_a.compare_f_test(model_fe_bps_pct_b)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_doubles_a.aic)\n",
    "print(\"BIC:\", model_fe_doubles_a.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_bps_pct_a.rsquared_adj)"
   ],
   "id": "1b57ab21d86811f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "1st Serve Win %"
    ]
   },
   "cell_type": "code",
   "source": [
    "# 1st serve win % metric creation & cleaning\n",
    "player_df = player_df.dropna(subset=['first_won', 'first_in'])\n",
    "player_df = player_df[player_df['first_won'] > 0]\n",
    "player_df = player_df[player_df['first_in'] > 0]\n",
    "player_df['first_serve_win_pct'] = player_df['first_won'] / player_df['first_in']\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_1sw_pct_a = smf.ols(\n",
    "    formula = 'first_serve_win_pct ~ round_num + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "print(model_fe_1sw_pct_a.summary())\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_1sw_pct_a.aic)\n",
    "print(\"BIC:\", model_fe_1sw_pct_a.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_1sw_pct_a.rsquared_adj)\n",
    "\n"
   ],
   "id": "a1ea230e9da5a225",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "1st Serve Win %",
     "Added Surface Control"
    ]
   },
   "cell_type": "code",
   "source": [
    "# 1st serve win % metric creation & cleaning\n",
    "player_df = player_df.dropna(subset=['first_won', 'first_in'])\n",
    "player_df = player_df[player_df['first_won'] > 0]\n",
    "player_df = player_df[player_df['first_in'] > 0]\n",
    "player_df['first_serve_win_pct'] = player_df['first_won'] / player_df['first_in']\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_1sw_pct_b = smf.ols(\n",
    "    formula = 'first_serve_win_pct ~ round_num + C(surface, Treatment(reference = \"Hard\")) + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "print(model_fe_1sw_pct_b.summary())\n",
    "\n",
    "# f-test\n",
    "f_stat, p_value, df_diff = model_fe_1sw_pct_a.compare_f_test(model_fe_1sw_pct_b)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_1sw_pct_b.aic)\n",
    "print(\"BIC:\", model_fe_1sw_pct_b.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_1sw_pct_b.rsquared_adj)"
   ],
   "id": "dc5d4c5be5d0c143",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "2nd Serve Win %"
    ]
   },
   "cell_type": "code",
   "source": [
    "# 2nd Serve Win % metric creation & cleaning\n",
    "player_df = player_df.dropna(subset=['second_won', 'svpt', 'double_faults', 'first_in'])\n",
    "player_df = player_df[player_df['second_won'] > 0]\n",
    "player_df = player_df[player_df['first_in'] > 0]\n",
    "player_df = player_df[player_df['svpt'] > 0]\n",
    "player_df = player_df[player_df['double_faults'] > 0]\n",
    "player_df['second_serve_att'] = player_df['svpt'] - player_df['first_in'] - player_df['double_faults']\n",
    "player_df = player_df[player_df['second_serve_att'] > 0]\n",
    "player_df['second_serve_win_pct'] = player_df['second_won'] / player_df['second_serve_att']\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_2sw_pct_a = smf.ols(\n",
    "    formula = 'second_serve_win_pct ~ round_num + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "print(model_fe_2sw_pct_a.summary())\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_2sw_pct_a.aic)\n",
    "print(\"BIC:\", model_fe_2sw_pct_a.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_2sw_pct_a.rsquared_adj)\n"
   ],
   "id": "2ac2a2420f29f058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "2nd Serve Win %",
     "Added Surface Control"
    ]
   },
   "cell_type": "code",
   "source": [
    "# 2nd Serve Win % metric creation & cleaning\n",
    "player_df = player_df.dropna(subset=['second_won', 'svpt', 'double_faults', 'first_in'])\n",
    "player_df = player_df[player_df['second_won'] > 0]\n",
    "player_df = player_df[player_df['first_in'] > 0]\n",
    "player_df = player_df[player_df['svpt'] > 0]\n",
    "player_df = player_df[player_df['double_faults'] > 0]\n",
    "player_df['second_serve_att'] = player_df['svpt'] - player_df['first_in'] - player_df['double_faults']\n",
    "player_df = player_df[player_df['second_serve_att'] > 0]\n",
    "player_df['second_serve_win_pct'] = player_df['second_won'] / player_df['second_serve_att']\n",
    "\n",
    "# sample creation\n",
    "top_players = player_df['player_name'].value_counts().head(25).index\n",
    "fe_df= player_df[player_df['player_name'].isin(top_players)].copy()\n",
    "fe_sample = fe_df.sample(1000, random_state=1)\n",
    "\n",
    "# model: two separate ones here because the surface model is a nested subset of the full model, and we want to compare based on the full model not a subset of it. If not, f_stat becomes -inf and p_value = nan\n",
    "model_fe_2sw_pct_b = smf.ols(\n",
    "    formula = 'second_serve_win_pct ~ round_num + C(surface, Treatment(reference = \"Hard\")) + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "print(model_fe_2sw_pct_b.summary())\n",
    "\n",
    "# f-test\n",
    "f_stat, p_value, df_diff = model_fe_2sw_pct_a.compare_f_test(model_fe_2sw_pct_b)\n",
    "print(f\"F-statistic: {f_stat:.4f}\")\n",
    "\n",
    "# AIC, BIC, and Adj. R-squared for Quality Control\n",
    "print(f\"p-value: {p_value:.4e}\")\n",
    "print(f\"Degrees of freedom (difference): {int(df_diff)}\")\n",
    "print(\"AIC:\", model_fe_2sw_pct_b.aic)\n",
    "print(\"BIC:\", model_fe_2sw_pct_b.bic)\n",
    "print(\"Adjusted R-squared:\", model_fe_2sw_pct_b.rsquared_adj)"
   ],
   "id": "ac7f68ad7c0f6acf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "Serve Performance Index"
    ]
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Define which raw variables go into the serve performance index\n",
    "performance_cols = [\n",
    "    'aces',\n",
    "    'double_faults',\n",
    "    'first_serve_pct',\n",
    "    'second_serve_pct',\n",
    "    'break_points_saved_pct',\n",
    "    'first_serve_win_pct',\n",
    "    'second_serve_win_pct'\n",
    "]\n",
    "\n",
    "# Step 2: Create a new DataFrame with relevant columns and drop missing rows\n",
    "metrics = player_df[['player_name', 'tourney_id', 'round_num', 'surface', 'year'] + performance_cols].copy()\n",
    "metrics = metrics.dropna()\n",
    "\n",
    "# Step 3: Z-score standardize the numerical performance metrics\n",
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(metrics[performance_cols])\n",
    "\n",
    "# Step 4: Assign back to a DataFrame with z_ column names\n",
    "z_colnames = [f'z_{col}' for col in performance_cols]\n",
    "scaled_df = pd.DataFrame(scaled_array, columns=z_colnames)\n",
    "\n",
    "# Step 5: Add back identifiers (player, surface, round, etc.)\n",
    "scaled_df_with_ids = pd.concat([metrics[['player_name', 'tourney_id', 'round_num', 'surface', 'year']].reset_index(drop=True), scaled_df], axis=1)\n",
    "\n",
    "# Step 6: Run PCA on the scaled performance metrics\n",
    "pca = PCA(n_components=1)\n",
    "serve_index_scores = pca.fit_transform(scaled_df[z_colnames])\n",
    "\n",
    "# Step 7: Save the PCA-based index and inspect weights\n",
    "scaled_df_with_ids['serve_performance_index'] = serve_index_scores\n",
    "weights = pd.Series(pca.components_[0], index=z_colnames)\n",
    "print(\"PCA Weights (Loadings):\")\n",
    "print(weights.sort_values())\n",
    "\n",
    "# Optional: visualize loading weights\n",
    "weights.sort_values().plot(kind='barh', title='PCA Loadings for Serve Performance Index')\n",
    "plt.xlabel('Loading Weight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "180a42216e9f7e44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "correlation check between first serve % and other serve metrics"
    ]
   },
   "cell_type": "code",
   "source": [
    "# heatmap to look at correlation across all metrics\n",
    "corr_matrix = metrics[num_columns].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Between Serve Metrics')\n",
    "plt.show()\n"
   ],
   "id": "657d8358f81f9a21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Serve Performance Index",
     "Fixed Effects Model"
    ]
   },
   "cell_type": "code",
   "source": [
    "# checking for proper columns\n",
    "print(scaled_df_with_ids.columns)\n",
    "\n",
    "# dropping NANs\n",
    "fe_df = scaled_df_with_ids.dropna(subset = ['serve_performance_index', 'round_num', 'player_name', 'surface'])\n",
    "# Sampling top 25 most active players\n",
    "top_players = fe_df['player_name'].value_counts().head(25).index\n",
    "fe_sample = fe_df[fe_df['player_name'].isin(top_players)].sample(1000, random_state = 1)\n",
    "\n",
    "print(fe_sample.shape)\n",
    "print(fe_sample['player_name'].nunique())\n",
    "\n",
    "# surface conversion\n",
    "fe_sample['surface'] = pd.Categorical(\n",
    "    fe_sample['surface'], categories = ['Hard', 'Clay', 'Grass'],\n",
    "    ordered = False)\n",
    "\n",
    "# regression\n",
    "import statsmodels.formula.api as smf\n",
    "model_perf = smf.ols(\n",
    "    formula = 'serve_performance_index ~ round_num + C(surface) + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "\n",
    "print(model_perf.summary())"
   ],
   "id": "d5238178ad1b7e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "tags": [
     "Fixed Effects Model",
     "Serve Performance Index",
     "Round num * Surface interaction term"
    ]
   },
   "cell_type": "code",
   "source": [
    "model_perf = smf.ols(\n",
    "    formula = 'serve_performance_index ~ round_num * C(surface) + C(player_name)',\n",
    "    data = fe_sample\n",
    ").fit()\n",
    "\n",
    "print(model_perf.summary())"
   ],
   "id": "fa4145f7758fd0f6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
